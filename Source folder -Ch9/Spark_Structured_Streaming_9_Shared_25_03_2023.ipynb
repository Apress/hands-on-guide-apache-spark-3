{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7bb0cb2-e2bd-4bf1-9b86-c4fe877e1430",
   "metadata": {},
   "source": [
    "#### Chapter 9. Event_Time_Window_Operations_and_Watermarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04029e94-c5d8-43f6-8f39-1e4dd96d6965",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://tucan:4040\n",
       "SparkContext available as 'sc' (version = 3.3.0, master = local[*], app id = local-1679606213124)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/23 22:17:02 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n",
      "\n",
      " Listening and ready... \n",
      "-------------------------------------------\n",
      "Batch: 0\n",
      "-------------------------------------------\n",
      "+------------------------------------------+----------+\n",
      "|window                                    |Suma_x_Dpt|\n",
      "+------------------------------------------+----------+\n",
      "|{2023-02-23 01:00:00, 2023-02-23 01:00:10}|1         |\n",
      "+------------------------------------------+----------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 1\n",
      "-------------------------------------------\n",
      "+------------------------------------------+----------+\n",
      "|window                                    |Suma_x_Dpt|\n",
      "+------------------------------------------+----------+\n",
      "|{2023-02-23 01:00:00, 2023-02-23 01:00:10}|3         |\n",
      "+------------------------------------------+----------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 2\n",
      "-------------------------------------------\n",
      "+------------------------------------------+----------+\n",
      "|window                                    |Suma_x_Dpt|\n",
      "+------------------------------------------+----------+\n",
      "|{2023-02-23 01:00:00, 2023-02-23 01:00:10}|6         |\n",
      "+------------------------------------------+----------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 3\n",
      "-------------------------------------------\n",
      "+------------------------------------------+----------+\n",
      "|window                                    |Suma_x_Dpt|\n",
      "+------------------------------------------+----------+\n",
      "|{2023-02-23 01:00:00, 2023-02-23 01:00:10}|10        |\n",
      "+------------------------------------------+----------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 4\n",
      "-------------------------------------------\n",
      "+------------------------------------------+----------+\n",
      "|window                                    |Suma_x_Dpt|\n",
      "+------------------------------------------+----------+\n",
      "|{2023-02-23 01:00:00, 2023-02-23 01:00:10}|10        |\n",
      "|{2023-02-23 01:00:10, 2023-02-23 01:00:20}|1         |\n",
      "+------------------------------------------+----------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 5\n",
      "-------------------------------------------\n",
      "+------------------------------------------+----------+\n",
      "|window                                    |Suma_x_Dpt|\n",
      "+------------------------------------------+----------+\n",
      "|{2023-02-23 01:00:00, 2023-02-23 01:00:10}|10        |\n",
      "|{2023-02-23 01:00:10, 2023-02-23 01:00:20}|1         |\n",
      "+------------------------------------------+----------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 6\n",
      "-------------------------------------------\n",
      "+------------------------------------------+----------+\n",
      "|window                                    |Suma_x_Dpt|\n",
      "+------------------------------------------+----------+\n",
      "|{2023-02-23 01:00:00, 2023-02-23 01:00:10}|10        |\n",
      "|{2023-02-23 01:00:10, 2023-02-23 01:00:20}|1         |\n",
      "+------------------------------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "// Tumbling windows \n",
    "\n",
    "import org.apache.spark.sql.SparkSession\n",
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.sql.types.{IntegerType, StringType, StructField, StructType,DoubleType,LongType}\n",
    "import org.apache.spark.sql.{DataFrame, Dataset, Encoders, SparkSession}\n",
    "import java.io.IOException\n",
    "import org.apache.spark.sql.streaming._\n",
    "import org.apache.spark.sql.streaming.{GroupState,GroupStateTimeout,OutputMode}\n",
    "import org.apache.spark.sql.DataFrame\n",
    "\n",
    "\n",
    "val PatientsSchema = StructType(Array(\n",
    "     StructField(\"NSS\", StringType),\n",
    "     StructField(\"Nom\", StringType),\n",
    "     StructField(\"DID\", IntegerType),\n",
    "     StructField(\"DNom\", StringType),\n",
    "     StructField(\"Fecha\", StringType)\n",
    "         )\n",
    "    )\n",
    "\n",
    "val spark:SparkSession = SparkSession.builder()\n",
    "    .master(\"local[10]\")\n",
    "    .appName(\"Hand-On-Spark3_Socket_Data_Source\")\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "\n",
    "import spark.implicits._\n",
    "\n",
    "\n",
    "try {\n",
    "    val PatientDS = spark.readStream\n",
    "        .schema(PatientsSchema)\n",
    "        .json(\"/tmp/window\")\n",
    "    \n",
    "    printf(\"\\n Listening and ready... \\n\")\n",
    "    \n",
    "    val PatientDF = PatientDS\n",
    "         .groupBy(window(col(\"Fecha\"), \"10 seconds\"))\n",
    "         .agg(count(\"DNom\").alias(\"Suma_x_Dpt\"))\n",
    "    \n",
    "    PatientDF.writeStream\n",
    "        .outputMode(\"complete\")\n",
    "        .format(\"console\")\n",
    "        .option(\"truncate\", false)\n",
    "        .start()\n",
    "        .awaitTermination()\n",
    "    \n",
    "} catch {\n",
    "    case e: IOException => println(\"IOException occurred\")\n",
    "    case t: Throwable => println(\"Error receiving data\", t)\n",
    "}finally {\n",
    "    println(\"In finally block\")\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8885aead-1005-4c55-9240-ff0aa44830e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Listening and ready... \n",
      "-------------------------------------------\n",
      "Batch: 0\n",
      "-------------------------------------------\n",
      "+-------------------+-------------------+----------+\n",
      "|start              |end                |Suma_x_Dpt|\n",
      "+-------------------+-------------------+----------+\n",
      "|2023-02-23 01:00:00|2023-02-23 01:00:10|1         |\n",
      "+-------------------+-------------------+----------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 1\n",
      "-------------------------------------------\n",
      "+-------------------+-------------------+----------+\n",
      "|start              |end                |Suma_x_Dpt|\n",
      "+-------------------+-------------------+----------+\n",
      "|2023-02-23 01:00:00|2023-02-23 01:00:10|3         |\n",
      "+-------------------+-------------------+----------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 2\n",
      "-------------------------------------------\n",
      "+-------------------+-------------------+----------+\n",
      "|start              |end                |Suma_x_Dpt|\n",
      "+-------------------+-------------------+----------+\n",
      "|2023-02-23 01:00:00|2023-02-23 01:00:10|6         |\n",
      "+-------------------+-------------------+----------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 3\n",
      "-------------------------------------------\n",
      "+-------------------+-------------------+----------+\n",
      "|start              |end                |Suma_x_Dpt|\n",
      "+-------------------+-------------------+----------+\n",
      "|2023-02-23 01:00:00|2023-02-23 01:00:10|10        |\n",
      "+-------------------+-------------------+----------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 4\n",
      "-------------------------------------------\n",
      "+-------------------+-------------------+----------+\n",
      "|start              |end                |Suma_x_Dpt|\n",
      "+-------------------+-------------------+----------+\n",
      "|2023-02-23 01:00:00|2023-02-23 01:00:10|10        |\n",
      "|2023-02-23 01:00:10|2023-02-23 01:00:20|1         |\n",
      "+-------------------+-------------------+----------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 5\n",
      "-------------------------------------------\n",
      "+-------------------+-------------------+----------+\n",
      "|start              |end                |Suma_x_Dpt|\n",
      "+-------------------+-------------------+----------+\n",
      "|2023-02-23 01:00:00|2023-02-23 01:00:10|10        |\n",
      "|2023-02-23 01:00:10|2023-02-23 01:00:20|1         |\n",
      "+-------------------+-------------------+----------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 6\n",
      "-------------------------------------------\n",
      "+-------------------+-------------------+----------+\n",
      "|start              |end                |Suma_x_Dpt|\n",
      "+-------------------+-------------------+----------+\n",
      "|2023-02-23 01:00:00|2023-02-23 01:00:10|10        |\n",
      "|2023-02-23 01:00:10|2023-02-23 01:00:20|1         |\n",
      "+-------------------+-------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// Tumbling windows II\n",
    "\n",
    "import org.apache.spark.sql.SparkSession\n",
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.sql.types.{IntegerType, StringType, StructField, StructType,DoubleType,LongType}\n",
    "import org.apache.spark.sql.{DataFrame, Dataset, Encoders, SparkSession}\n",
    "import java.io.IOException\n",
    "import org.apache.spark.sql.streaming._\n",
    "import org.apache.spark.sql.streaming.{GroupState,GroupStateTimeout,OutputMode}\n",
    "import org.apache.spark.sql.DataFrame\n",
    "\n",
    "\n",
    "val PatientsSchema = StructType(Array(\n",
    "     StructField(\"NSS\", StringType),\n",
    "     StructField(\"Nom\", StringType),\n",
    "     StructField(\"DID\", IntegerType),\n",
    "     StructField(\"DNom\", StringType),\n",
    "     StructField(\"Fecha\", StringType)\n",
    "         )\n",
    "    )\n",
    "\n",
    "val spark:SparkSession = SparkSession.builder()\n",
    "    .master(\"local[10]\")\n",
    "    .appName(\"Hand-On-Spark3_Socket_Data_Source\")\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "\n",
    "import spark.implicits._\n",
    "\n",
    "\n",
    "try {\n",
    "    val PatientDS = spark.readStream\n",
    "        .schema(PatientsSchema)\n",
    "        .json(\"/tmp/window\")\n",
    "    \n",
    "    printf(\"\\n Listening and ready... \\n\")\n",
    "    \n",
    "    val PatientDF = PatientDS\n",
    "        .groupBy(window(col(\"Fecha\"), \"10 seconds\"))\n",
    "        .agg(count(\"DNom\").alias(\"Suma_x_Dpt\"))\n",
    "        .select(\"window.start\", \"window.end\", \"Suma_x_Dpt\")\n",
    "    \n",
    "    PatientDF.writeStream\n",
    "        .outputMode(\"complete\")\n",
    "        .format(\"console\")\n",
    "        .option(\"truncate\", false)\n",
    "        .start()\n",
    "        .awaitTermination()\n",
    "    \n",
    "} catch {\n",
    "    case e: IOException => println(\"IOException occurred\")\n",
    "    case t: Throwable => println(\"Error receiving data\", t)\n",
    "}finally {\n",
    "    println(\"In finally block\")\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e10d8e3-80c8-4d00-b00d-77c5bbde2246",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://tucan:4040\n",
       "SparkContext available as 'sc' (version = 3.3.0, master = local[*], app id = local-1679653303380)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/24 11:21:52 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n",
      "\n",
      " Listening and ready... \n",
      "-------------------------------------------\n",
      "Batch: 0\n",
      "-------------------------------------------\n",
      "+------------------------------------------+----------+\n",
      "|window                                    |Suma_x_Dpt|\n",
      "+------------------------------------------+----------+\n",
      "|{2023-02-23 01:00:25, 2023-02-23 01:00:35}|5         |\n",
      "|{2023-02-23 01:00:35, 2023-02-23 01:00:45}|4         |\n",
      "|{2023-02-23 01:00:30, 2023-02-23 01:00:40}|9         |\n",
      "+------------------------------------------+----------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 1\n",
      "-------------------------------------------\n",
      "+------------------------------------------+----------+\n",
      "|window                                    |Suma_x_Dpt|\n",
      "+------------------------------------------+----------+\n",
      "|{2023-02-23 01:00:25, 2023-02-23 01:00:35}|10        |\n",
      "|{2023-02-23 01:00:20, 2023-02-23 01:00:30}|8         |\n",
      "|{2023-02-23 01:00:35, 2023-02-23 01:00:45}|4         |\n",
      "|{2023-02-23 01:00:30, 2023-02-23 01:00:40}|9         |\n",
      "|{2023-02-23 01:00:15, 2023-02-23 01:00:25}|3         |\n",
      "+------------------------------------------+----------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 2\n",
      "-------------------------------------------\n",
      "+------------------------------------------+----------+\n",
      "|window                                    |Suma_x_Dpt|\n",
      "+------------------------------------------+----------+\n",
      "|{2023-02-23 01:00:25, 2023-02-23 01:00:35}|10        |\n",
      "|{2023-02-23 01:00:20, 2023-02-23 01:00:30}|10        |\n",
      "|{2023-02-23 01:00:35, 2023-02-23 01:00:45}|4         |\n",
      "|{2023-02-23 01:00:10, 2023-02-23 01:00:20}|5         |\n",
      "|{2023-02-23 01:00:30, 2023-02-23 01:00:40}|9         |\n",
      "|{2023-02-23 01:00:15, 2023-02-23 01:00:25}|10        |\n",
      "+------------------------------------------+----------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 3\n",
      "-------------------------------------------\n",
      "+------------------------------------------+----------+\n",
      "|window                                    |Suma_x_Dpt|\n",
      "+------------------------------------------+----------+\n",
      "|{2023-02-23 01:00:25, 2023-02-23 01:00:35}|10        |\n",
      "|{2023-02-23 01:00:20, 2023-02-23 01:00:30}|11        |\n",
      "|{2023-02-23 01:00:35, 2023-02-23 01:00:45}|4         |\n",
      "|{2023-02-23 01:00:10, 2023-02-23 01:00:20}|10        |\n",
      "|{2023-02-23 01:00:30, 2023-02-23 01:00:40}|9         |\n",
      "|{2023-02-23 01:00:15, 2023-02-23 01:00:25}|16        |\n",
      "+------------------------------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "// Sliding Windows\n",
    "\n",
    "import org.apache.spark.sql.SparkSession\n",
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.sql.types.{IntegerType, StringType, StructField, StructType,DoubleType,LongType}\n",
    "import org.apache.spark.sql.{DataFrame, Dataset, Encoders, SparkSession}\n",
    "import java.io.IOException\n",
    "import org.apache.spark.sql.streaming._\n",
    "import org.apache.spark.sql.streaming.{GroupState,GroupStateTimeout,OutputMode}\n",
    "import org.apache.spark.sql.DataFrame\n",
    "\n",
    "\n",
    "val PatientsSchema = StructType(Array(\n",
    "     StructField(\"NSS\", StringType),\n",
    "     StructField(\"Nom\", StringType),\n",
    "     StructField(\"DID\", IntegerType),\n",
    "     StructField(\"DNom\", StringType),\n",
    "     StructField(\"Fecha\", StringType)\n",
    "         )\n",
    "    )\n",
    "\n",
    "val spark:SparkSession = SparkSession.builder()\n",
    "    .master(\"local[10]\")\n",
    "    .appName(\"Hand-On-Spark3_Socket_Data_Source\")\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "\n",
    "import spark.implicits._\n",
    "\n",
    "try {\n",
    "    val PatientDS = spark.readStream\n",
    "        .schema(PatientsSchema)\n",
    "        .json(\"/tmp/window\")\n",
    "    \n",
    "    printf(\"\\n Listening and ready... \\n\")\n",
    "    \n",
    "    val PatientDF = PatientDS\n",
    "         .groupBy(window(col(\"Fecha\"), \"10 seconds\", \"5 seconds\"))\n",
    "         .agg(count(\"DID\").alias(\"Suma_x_Dpt\"))\n",
    "    \n",
    "    PatientDF.writeStream\n",
    "        .outputMode(\"complete\")\n",
    "        .format(\"console\")\n",
    "        .option(\"truncate\", false)\n",
    "        .start()\n",
    "        .awaitTermination()\n",
    "    \n",
    "} catch {\n",
    "    case e: IOException => println(\"IOException occurred\")\n",
    "    case t: Throwable => println(\"Error receiving data\", t)\n",
    "}finally {\n",
    "    println(\"In finally block\")\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e67d466-7ec9-4579-b417-f3e9a64766b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Listening and ready... \n",
      "-------------------------------------------\n",
      "Batch: 0\n",
      "-------------------------------------------\n",
      "+-------------------+-------------------+----------+\n",
      "|start              |end                |Suma_x_Dpt|\n",
      "+-------------------+-------------------+----------+\n",
      "|2023-02-23 01:00:25|2023-02-23 01:00:35|5         |\n",
      "|2023-02-23 01:00:35|2023-02-23 01:00:45|4         |\n",
      "|2023-02-23 01:00:30|2023-02-23 01:00:40|9         |\n",
      "+-------------------+-------------------+----------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 1\n",
      "-------------------------------------------\n",
      "+-------------------+-------------------+----------+\n",
      "|start              |end                |Suma_x_Dpt|\n",
      "+-------------------+-------------------+----------+\n",
      "|2023-02-23 01:00:25|2023-02-23 01:00:35|10        |\n",
      "|2023-02-23 01:00:20|2023-02-23 01:00:30|8         |\n",
      "|2023-02-23 01:00:35|2023-02-23 01:00:45|4         |\n",
      "|2023-02-23 01:00:30|2023-02-23 01:00:40|9         |\n",
      "|2023-02-23 01:00:15|2023-02-23 01:00:25|3         |\n",
      "+-------------------+-------------------+----------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 2\n",
      "-------------------------------------------\n",
      "+-------------------+-------------------+----------+\n",
      "|start              |end                |Suma_x_Dpt|\n",
      "+-------------------+-------------------+----------+\n",
      "|2023-02-23 01:00:25|2023-02-23 01:00:35|10        |\n",
      "|2023-02-23 01:00:20|2023-02-23 01:00:30|10        |\n",
      "|2023-02-23 01:00:35|2023-02-23 01:00:45|4         |\n",
      "|2023-02-23 01:00:10|2023-02-23 01:00:20|5         |\n",
      "|2023-02-23 01:00:30|2023-02-23 01:00:40|9         |\n",
      "|2023-02-23 01:00:15|2023-02-23 01:00:25|10        |\n",
      "+-------------------+-------------------+----------+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 3\n",
      "-------------------------------------------\n",
      "+-------------------+-------------------+----------+\n",
      "|start              |end                |Suma_x_Dpt|\n",
      "+-------------------+-------------------+----------+\n",
      "|2023-02-23 01:00:25|2023-02-23 01:00:35|10        |\n",
      "|2023-02-23 01:00:20|2023-02-23 01:00:30|11        |\n",
      "|2023-02-23 01:00:35|2023-02-23 01:00:45|4         |\n",
      "|2023-02-23 01:00:10|2023-02-23 01:00:20|10        |\n",
      "|2023-02-23 01:00:30|2023-02-23 01:00:40|9         |\n",
      "|2023-02-23 01:00:15|2023-02-23 01:00:25|16        |\n",
      "+-------------------+-------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "// Sliding Windows II\n",
    "\n",
    "import org.apache.spark.sql.SparkSession\n",
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.sql.types.{IntegerType, StringType, StructField, StructType,DoubleType,LongType}\n",
    "import org.apache.spark.sql.{DataFrame, Dataset, Encoders, SparkSession}\n",
    "import java.io.IOException\n",
    "import org.apache.spark.sql.streaming._\n",
    "import org.apache.spark.sql.streaming.{GroupState,GroupStateTimeout,OutputMode}\n",
    "import org.apache.spark.sql.DataFrame\n",
    "\n",
    "\n",
    "val PatientsSchema = StructType(Array(\n",
    "     StructField(\"NSS\", StringType),\n",
    "     StructField(\"Nom\", StringType),\n",
    "     StructField(\"DID\", IntegerType),\n",
    "     StructField(\"DNom\", StringType),\n",
    "     StructField(\"Fecha\", StringType)\n",
    "         )\n",
    "    )\n",
    "val spark:SparkSession = SparkSession.builder()\n",
    "    .master(\"local[10]\")\n",
    "    .appName(\"Hand-On-Spark3_Socket_Data_Source\")\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "\n",
    "import spark.implicits._\n",
    "\n",
    "try {\n",
    "    val PatientDS = spark.readStream\n",
    "        .schema(PatientsSchema)\n",
    "        .json(\"/tmp/window\")\n",
    "    \n",
    "    printf(\"\\n Listening and ready... \\n\")\n",
    "    \n",
    "    val PatientDF = PatientDS\n",
    "        .groupBy(window(col(\"Fecha\"), \"10 seconds\", \"5 seconds\"))\n",
    "        .agg(count(\"DID\").alias(\"Suma_x_Dpt\"))\n",
    "        .select(\"window.start\", \"window.end\", \"Suma_x_Dpt\")\n",
    "    \n",
    "    PatientDF.writeStream\n",
    "        .outputMode(\"complete\")\n",
    "        .format(\"console\")\n",
    "        .option(\"truncate\", false)\n",
    "        .start()\n",
    "        .awaitTermination()\n",
    "    \n",
    "} catch {\n",
    "    case e: IOException => println(\"IOException occurred\")\n",
    "    case t: Throwable => println(\"Error receiving data\", t)\n",
    "}finally {\n",
    "    println(\"In finally block\")\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de431284-092d-435e-ae5b-d962a7777a4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://tucan:4040\n",
       "SparkContext available as 'sc' (version = 3.3.0, master = local[*], app id = local-1679673766384)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/24 17:02:55 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n",
      "root\n",
      " |-- NSS: string (nullable = true)\n",
      " |-- Nom: string (nullable = true)\n",
      " |-- DID: integer (nullable = true)\n",
      " |-- DNom: string (nullable = true)\n",
      " |-- Fecha: string (nullable = true)\n",
      "\n",
      "\n",
      " Listening and ready... \n",
      "root\n",
      " |-- session_window: struct (nullable = false)\n",
      " |    |-- start: timestamp (nullable = true)\n",
      " |    |-- end: timestamp (nullable = true)\n",
      " |-- DID: integer (nullable = true)\n",
      " |-- count: long (nullable = false)\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 0\n",
      "-------------------------------------------\n",
      "+--------------------------------------------------+---+-----+\n",
      "|session_window                                    |DID|count|\n",
      "+--------------------------------------------------+---+-----+\n",
      "|{2023-02-23 01:00:15.002, 2023-02-23 01:00:25.002}|20 |1    |\n",
      "|{2023-02-23 01:00:18.002, 2023-02-23 01:00:31.002}|10 |4    |\n",
      "|{2023-02-23 01:00:17.002, 2023-02-23 01:00:27.002}|50 |1    |\n",
      "|{2023-02-23 01:00:16.002, 2023-02-23 01:00:26.002}|30 |1    |\n",
      "+--------------------------------------------------+---+-----+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 1\n",
      "-------------------------------------------\n",
      "+--------------------------------------------------+---+-----+\n",
      "|session_window                                    |DID|count|\n",
      "+--------------------------------------------------+---+-----+\n",
      "|{2023-02-23 01:00:15.002, 2023-02-23 01:00:25.002}|20 |2    |\n",
      "|{2023-02-23 01:00:18.002, 2023-02-23 01:00:31.002}|10 |7    |\n",
      "|{2023-02-23 01:00:17.002, 2023-02-23 01:00:27.002}|50 |2    |\n",
      "|{2023-02-23 01:00:16.002, 2023-02-23 01:00:26.002}|30 |2    |\n",
      "+--------------------------------------------------+---+-----+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 2\n",
      "-------------------------------------------\n",
      "+--------------------------------------------------+---+-----+\n",
      "|session_window                                    |DID|count|\n",
      "+--------------------------------------------------+---+-----+\n",
      "|{2023-02-23 01:02:00.002, 2023-02-23 01:02:10.002}|20 |1    |\n",
      "|{2023-02-23 01:00:15.002, 2023-02-23 01:00:25.002}|20 |2    |\n",
      "|{2023-02-23 01:01:34.002, 2023-02-23 01:01:44.002}|20 |1    |\n",
      "|{2023-02-23 01:02:05.002, 2023-02-23 01:02:15.002}|10 |1    |\n",
      "|{2023-02-23 01:00:18.002, 2023-02-23 01:00:31.002}|10 |7    |\n",
      "|{2023-02-23 01:00:17.002, 2023-02-23 01:00:27.002}|50 |2    |\n",
      "|{2023-02-23 01:02:20.002, 2023-02-23 01:02:30.002}|50 |1    |\n",
      "|{2023-02-23 01:02:38.002, 2023-02-23 01:02:48.002}|50 |1    |\n",
      "|{2023-02-23 01:01:30.002, 2023-02-23 01:01:43.002}|50 |4    |\n",
      "|{2023-02-23 01:02:37.002, 2023-02-23 01:02:47.002}|30 |1    |\n",
      "|{2023-02-23 01:00:16.002, 2023-02-23 01:00:26.002}|30 |2    |\n",
      "|{2023-02-23 01:02:10.002, 2023-02-23 01:02:20.002}|30 |1    |\n",
      "+--------------------------------------------------+---+-----+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 3\n",
      "-------------------------------------------\n",
      "+--------------------------------------------------+---+-----+\n",
      "|session_window                                    |DID|count|\n",
      "+--------------------------------------------------+---+-----+\n",
      "|{2023-02-23 01:00:15.002, 2023-02-23 01:00:25.002}|20 |2    |\n",
      "|{2023-02-23 01:01:34.002, 2023-02-23 01:01:44.002}|20 |1    |\n",
      "|{2023-02-23 01:00:34.002, 2023-02-23 01:00:45.002}|20 |2    |\n",
      "|{2023-02-23 01:02:00.002, 2023-02-23 01:02:10.002}|20 |1    |\n",
      "|{2023-02-23 01:00:18.002, 2023-02-23 01:00:31.002}|10 |7    |\n",
      "|{2023-02-23 01:02:05.002, 2023-02-23 01:02:15.002}|10 |1    |\n",
      "|{2023-02-23 01:00:36.002, 2023-02-23 01:00:46.002}|10 |1    |\n",
      "|{2023-02-23 01:02:20.002, 2023-02-23 01:02:30.002}|50 |1    |\n",
      "|{2023-02-23 01:00:17.002, 2023-02-23 01:00:27.002}|50 |2    |\n",
      "|{2023-02-23 01:00:30.002, 2023-02-23 01:00:48.002}|50 |5    |\n",
      "|{2023-02-23 01:02:38.002, 2023-02-23 01:02:48.002}|50 |1    |\n",
      "|{2023-02-23 01:01:30.002, 2023-02-23 01:01:43.002}|50 |4    |\n",
      "|{2023-02-23 01:00:16.002, 2023-02-23 01:00:26.002}|30 |2    |\n",
      "|{2023-02-23 01:02:10.002, 2023-02-23 01:02:20.002}|30 |1    |\n",
      "|{2023-02-23 01:00:37.002, 2023-02-23 01:00:47.002}|30 |1    |\n",
      "|{2023-02-23 01:02:37.002, 2023-02-23 01:02:47.002}|30 |1    |\n",
      "+--------------------------------------------------+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "// Session Windows I\n",
    "\n",
    "import org.apache.spark.sql.SparkSession\n",
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.sql.types._\n",
    "import org.apache.spark.sql.{DataFrame, Dataset, Encoders, SparkSession}\n",
    "import java.io.IOException\n",
    "import org.apache.spark.sql.streaming._\n",
    "import org.apache.spark.sql.streaming.{GroupState,GroupStateTimeout,OutputMode}\n",
    "import org.apache.spark.sql.DataFrame\n",
    "\n",
    "\n",
    "val PatientsSchema = StructType(Array(\n",
    "     StructField(\"NSS\", StringType),\n",
    "     StructField(\"Nom\", StringType),\n",
    "     StructField(\"DID\", IntegerType),\n",
    "     StructField(\"DNom\", StringType),\n",
    "     StructField(\"Fecha\", StringType)\n",
    "         )\n",
    "    )\n",
    "val spark:SparkSession = SparkSession.builder()\n",
    "    .master(\"local[10]\")\n",
    "    .appName(\"Hand-On-Spark3_Socket_Data_Source\")\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "\n",
    "import spark.implicits._\n",
    "\n",
    "try {\n",
    "    val PatientDS = spark.readStream\n",
    "        .schema(PatientsSchema)\n",
    "        .json(\"/tmp/window\")\n",
    "    \n",
    "    PatientDS.printSchema()\n",
    "    \n",
    "    printf(\"\\n Listening and ready... \\n\")\n",
    "\n",
    "    val PatientDF = PatientDS\n",
    "        .groupBy(\n",
    "            session_window(col(\"Fecha\"), \"10 seconds\"), col(\"DID\")\n",
    "        ).count()\n",
    "    \n",
    "    PatientDF.printSchema()\n",
    "    \n",
    "    PatientDF.writeStream\n",
    "        .outputMode(\"complete\")\n",
    "        .format(\"console\")\n",
    "        .option(\"truncate\", false)\n",
    "        .start()\n",
    "        .awaitTermination()\n",
    "    \n",
    "} catch {\n",
    "    case e: IOException => println(\"IOException occurred\")\n",
    "    case t: Throwable => println(\"Error receiving data\", t)\n",
    "}finally {\n",
    "    println(\"In finally block\")\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca30e2e7-398e-4db4-914b-5a25c24ab277",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://tucan:4040\n",
       "SparkContext available as 'sc' (version = 3.3.0, master = local[*], app id = local-1679677806552)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/24 18:10:15 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n",
      "root\n",
      " |-- NSS: string (nullable = true)\n",
      " |-- Nom: string (nullable = true)\n",
      " |-- DID: integer (nullable = true)\n",
      " |-- DNom: string (nullable = true)\n",
      " |-- Fecha: string (nullable = true)\n",
      "\n",
      "\n",
      " Listening and ready... \n",
      "root\n",
      " |-- session_window: struct (nullable = false)\n",
      " |    |-- start: timestamp (nullable = true)\n",
      " |    |-- end: timestamp (nullable = true)\n",
      " |-- DID: integer (nullable = true)\n",
      " |-- count: long (nullable = false)\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 0\n",
      "-------------------------------------------\n",
      "+--------------------------------------------------+---+-----+\n",
      "|session_window                                    |DID|count|\n",
      "+--------------------------------------------------+---+-----+\n",
      "|{2023-02-23 01:00:15.002, 2023-02-23 01:00:25.002}|20 |1    |\n",
      "|{2023-02-23 01:00:18.002, 2023-02-23 01:01:20.002}|10 |3    |\n",
      "|{2023-02-23 01:00:17.002, 2023-02-23 01:01:17.002}|50 |1    |\n",
      "|{2023-02-23 01:00:16.002, 2023-02-23 01:01:16.002}|30 |1    |\n",
      "+--------------------------------------------------+---+-----+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 1\n",
      "-------------------------------------------\n",
      "+--------------------------------------------------+---+-----+\n",
      "|session_window                                    |DID|count|\n",
      "+--------------------------------------------------+---+-----+\n",
      "|{2023-02-23 01:00:15.002, 2023-02-23 01:00:45.002}|20 |2    |\n",
      "|{2023-02-23 01:00:18.002, 2023-02-23 01:01:21.002}|10 |7    |\n",
      "|{2023-02-23 01:00:17.002, 2023-02-23 01:01:17.002}|50 |2    |\n",
      "|{2023-02-23 01:00:16.002, 2023-02-23 01:01:16.002}|30 |2    |\n",
      "+--------------------------------------------------+---+-----+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 2\n",
      "-------------------------------------------\n",
      "+--------------------------------------------------+---+-----+\n",
      "|session_window                                    |DID|count|\n",
      "+--------------------------------------------------+---+-----+\n",
      "|{2023-02-23 01:00:15.002, 2023-02-23 01:01:22.002}|20 |3    |\n",
      "|{2023-02-23 01:00:18.002, 2023-02-23 01:01:28.002}|10 |11   |\n",
      "|{2023-02-23 01:00:17.002, 2023-02-23 01:01:29.002}|50 |4    |\n",
      "|{2023-02-23 01:00:16.002, 2023-02-23 01:01:23.002}|30 |3    |\n",
      "+--------------------------------------------------+---+-----+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 3\n",
      "-------------------------------------------\n",
      "+--------------------------------------------------+---+-----+\n",
      "|session_window                                    |DID|count|\n",
      "+--------------------------------------------------+---+-----+\n",
      "|{2023-02-23 01:00:15.002, 2023-02-23 01:01:35.002}|20 |5    |\n",
      "|{2023-02-23 01:00:18.002, 2023-02-23 01:01:36.002}|10 |12   |\n",
      "|{2023-02-23 01:00:17.002, 2023-02-23 01:01:38.002}|50 |9    |\n",
      "|{2023-02-23 01:00:16.002, 2023-02-23 01:01:37.002}|30 |4    |\n",
      "+--------------------------------------------------+---+-----+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 4\n",
      "-------------------------------------------\n",
      "+--------------------------------------------------+---+-----+\n",
      "|session_window                                    |DID|count|\n",
      "+--------------------------------------------------+---+-----+\n",
      "|{2023-02-23 01:00:15.002, 2023-02-23 01:03:00.002}|20 |7    |\n",
      "|{2023-02-23 01:02:05.002, 2023-02-23 01:03:05.002}|10 |1    |\n",
      "|{2023-02-23 01:00:18.002, 2023-02-23 01:01:36.002}|10 |12   |\n",
      "|{2023-02-23 01:00:17.002, 2023-02-23 01:03:38.002}|50 |15   |\n",
      "|{2023-02-23 01:00:16.002, 2023-02-23 01:01:37.002}|30 |4    |\n",
      "|{2023-02-23 01:02:10.002, 2023-02-23 01:03:37.002}|30 |2    |\n",
      "+--------------------------------------------------+---+-----+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 5\n",
      "-------------------------------------------\n",
      "+--------------------------------------------------+---+-----+\n",
      "|session_window                                    |DID|count|\n",
      "+--------------------------------------------------+---+-----+\n",
      "|{2023-02-23 01:00:15.002, 2023-02-23 01:03:00.002}|20 |7    |\n",
      "|{2023-02-23 01:00:18.002, 2023-02-23 01:01:36.002}|10 |12   |\n",
      "|{2023-02-23 01:02:05.002, 2023-02-23 01:03:05.002}|10 |1    |\n",
      "|{2023-02-23 01:00:17.002, 2023-02-23 01:03:38.002}|50 |15   |\n",
      "|{2023-02-23 01:02:10.002, 2023-02-23 01:03:37.002}|30 |2    |\n",
      "|{2023-02-23 01:00:10.002, 2023-02-23 01:01:37.002}|30 |5    |\n",
      "+--------------------------------------------------+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// Session window with dynamic gap duration\n",
    "\n",
    "// Session Windows II\n",
    "\n",
    "import org.apache.spark.sql.SparkSession\n",
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.sql.types._\n",
    "import org.apache.spark.sql.{DataFrame, Dataset, Encoders, SparkSession}\n",
    "import java.io.IOException\n",
    "import org.apache.spark.sql.streaming._\n",
    "import org.apache.spark.sql.streaming.{GroupState,GroupStateTimeout,OutputMode}\n",
    "import org.apache.spark.sql.DataFrame\n",
    "\n",
    "\n",
    "val PatientsSchema = StructType(Array(\n",
    "     StructField(\"NSS\", StringType),\n",
    "     StructField(\"Nom\", StringType),\n",
    "     StructField(\"DID\", IntegerType),\n",
    "     StructField(\"DNom\", StringType),\n",
    "     StructField(\"Fecha\", StringType)\n",
    "         )\n",
    "    )\n",
    "val spark:SparkSession = SparkSession.builder()\n",
    "    .master(\"local[10]\")\n",
    "    .appName(\"Hand-On-Spark3_Socket_Data_Source\")\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "\n",
    "import spark.implicits._\n",
    "\n",
    "try {\n",
    "    val PatientDS = spark.readStream\n",
    "        .schema(PatientsSchema)\n",
    "        .json(\"/tmp/window\")\n",
    "    \n",
    "    PatientDS.printSchema()\n",
    "    \n",
    "    printf(\"\\n Listening and ready... \\n\")\n",
    "\n",
    "    val PatientDF = PatientDS\n",
    "        .groupBy(\n",
    "            session_window(col(\"Fecha\"), \n",
    "                           when(col(\"NSS\") === \"1009\", \"10 seconds\")\n",
    "                           .when(col(\"NSS\") === \"2001\", \"30 seconds\")\n",
    "                           .when(col(\"NSS\") === \"5000\", \"50 seconds\")\n",
    "                           .otherwise(\"60 seconds\")),\n",
    "            col(\"DID\")\n",
    "        ).count()\n",
    "    \n",
    "    PatientDF.printSchema()\n",
    "    \n",
    "    PatientDF.writeStream\n",
    "        .outputMode(\"complete\")\n",
    "        .format(\"console\")\n",
    "        .option(\"truncate\", false)\n",
    "        .start()\n",
    "        .awaitTermination()\n",
    "    \n",
    "} catch {\n",
    "    case e: IOException => println(\"IOException occurred\")\n",
    "    case t: Throwable => println(\"Error receiving data\", t)\n",
    "}finally {\n",
    "    println(\"In finally block\")\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82238a31-9392-406a-97d8-89f8f1c61330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- NSS: string (nullable = true)\n",
      " |-- Nom: string (nullable = true)\n",
      " |-- DID: integer (nullable = true)\n",
      " |-- DNom: string (nullable = true)\n",
      " |-- Fecha: timestamp (nullable = true)\n",
      "\n",
      "\n",
      " Listening and ready... \n",
      "root\n",
      " |-- session_window: struct (nullable = false)\n",
      " |    |-- start: timestamp (nullable = true)\n",
      " |    |-- end: timestamp (nullable = true)\n",
      " |-- DID: integer (nullable = true)\n",
      " |-- count: long (nullable = false)\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 0\n",
      "-------------------------------------------\n",
      "+--------------------------------------------------+---+-----+\n",
      "|session_window                                    |DID|count|\n",
      "+--------------------------------------------------+---+-----+\n",
      "|{2023-02-23 01:01:34.002, 2023-02-23 01:01:44.002}|20 |1    |\n",
      "|{2023-02-23 01:02:00.002, 2023-02-23 01:02:10.002}|20 |1    |\n",
      "|{2023-02-23 01:02:05.002, 2023-02-23 01:02:15.002}|10 |1    |\n",
      "|{2023-02-23 01:02:20.002, 2023-02-23 01:02:30.002}|50 |1    |\n",
      "|{2023-02-23 01:02:38.002, 2023-02-23 01:02:48.002}|50 |1    |\n",
      "|{2023-02-23 01:01:30.002, 2023-02-23 01:01:43.002}|50 |4    |\n",
      "|{2023-02-23 01:02:10.002, 2023-02-23 01:02:20.002}|30 |1    |\n",
      "|{2023-02-23 01:02:37.002, 2023-02-23 01:02:47.002}|30 |1    |\n",
      "+--------------------------------------------------+---+-----+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 1\n",
      "-------------------------------------------\n",
      "+--------------------------------------------------+---+-----+\n",
      "|session_window                                    |DID|count|\n",
      "+--------------------------------------------------+---+-----+\n",
      "|{2023-02-23 01:02:00.002, 2023-02-23 01:02:10.002}|20 |1    |\n",
      "|{2023-02-23 01:01:34.002, 2023-02-23 01:01:44.002}|20 |1    |\n",
      "|{2023-02-23 01:02:05.002, 2023-02-23 01:02:15.002}|10 |1    |\n",
      "|{2023-02-23 01:02:20.002, 2023-02-23 01:02:30.002}|50 |1    |\n",
      "|{2023-02-23 01:02:38.002, 2023-02-23 01:02:48.002}|50 |1    |\n",
      "|{2023-02-23 01:01:30.002, 2023-02-23 01:01:43.002}|50 |4    |\n",
      "|{2023-02-23 01:02:37.002, 2023-02-23 01:02:47.002}|30 |1    |\n",
      "|{2023-02-23 01:02:10.002, 2023-02-23 01:02:20.002}|30 |1    |\n",
      "+--------------------------------------------------+---+-----+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 2\n",
      "-------------------------------------------\n",
      "+--------------------------------------------------+---+-----+\n",
      "|session_window                                    |DID|count|\n",
      "+--------------------------------------------------+---+-----+\n",
      "|{2023-02-23 01:02:00.002, 2023-02-23 01:02:10.002}|20 |1    |\n",
      "|{2023-02-23 01:01:34.002, 2023-02-23 01:01:44.002}|20 |1    |\n",
      "|{2023-02-23 01:02:05.002, 2023-02-23 01:02:15.002}|10 |1    |\n",
      "|{2023-02-23 01:02:20.002, 2023-02-23 01:02:30.002}|50 |1    |\n",
      "|{2023-02-23 01:02:38.002, 2023-02-23 01:02:48.002}|50 |1    |\n",
      "|{2023-02-23 01:01:30.002, 2023-02-23 01:01:43.002}|50 |4    |\n",
      "|{2023-02-23 01:02:37.002, 2023-02-23 01:02:47.002}|30 |1    |\n",
      "|{2023-02-23 01:02:10.002, 2023-02-23 01:02:20.002}|30 |1    |\n",
      "+--------------------------------------------------+---+-----+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 3\n",
      "-------------------------------------------\n",
      "+--------------------------------------------------+---+-----+\n",
      "|session_window                                    |DID|count|\n",
      "+--------------------------------------------------+---+-----+\n",
      "|{2023-02-23 01:02:00.002, 2023-02-23 01:02:10.002}|20 |1    |\n",
      "|{2023-02-23 01:01:34.002, 2023-02-23 01:01:44.002}|20 |1    |\n",
      "|{2023-02-23 01:02:05.002, 2023-02-23 01:02:15.002}|10 |1    |\n",
      "|{2023-02-23 01:02:20.002, 2023-02-23 01:02:30.002}|50 |1    |\n",
      "|{2023-02-23 01:02:38.002, 2023-02-23 01:02:48.002}|50 |1    |\n",
      "|{2023-02-23 01:01:30.002, 2023-02-23 01:01:43.002}|50 |4    |\n",
      "|{2023-02-23 01:02:37.002, 2023-02-23 01:02:47.002}|30 |1    |\n",
      "|{2023-02-23 01:02:10.002, 2023-02-23 01:02:20.002}|30 |1    |\n",
      "+--------------------------------------------------+---+-----+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 4\n",
      "-------------------------------------------\n",
      "+--------------------------------------------------+---+-----+\n",
      "|session_window                                    |DID|count|\n",
      "+--------------------------------------------------+---+-----+\n",
      "|{2023-02-23 01:02:00.002, 2023-02-23 01:02:10.002}|20 |1    |\n",
      "|{2023-02-23 01:01:34.002, 2023-02-23 01:01:44.002}|20 |1    |\n",
      "|{2023-02-23 01:02:05.002, 2023-02-23 01:02:15.002}|10 |1    |\n",
      "|{2023-02-23 01:02:20.002, 2023-02-23 01:02:30.002}|50 |1    |\n",
      "|{2023-02-23 01:02:38.002, 2023-02-23 01:02:48.002}|50 |1    |\n",
      "|{2023-02-23 01:01:30.002, 2023-02-23 01:01:43.002}|50 |4    |\n",
      "|{2023-02-23 01:02:37.002, 2023-02-23 01:02:47.002}|30 |1    |\n",
      "|{2023-02-23 01:02:10.002, 2023-02-23 01:02:20.002}|30 |1    |\n",
      "+--------------------------------------------------+---+-----+\n",
      "\n",
      "-------------------------------------------\n",
      "Batch: 5\n",
      "-------------------------------------------\n",
      "+--------------------------------------------------+---+-----+\n",
      "|session_window                                    |DID|count|\n",
      "+--------------------------------------------------+---+-----+\n",
      "|{2023-02-23 01:02:00.002, 2023-02-23 01:02:10.002}|20 |1    |\n",
      "|{2023-02-23 01:01:34.002, 2023-02-23 01:01:44.002}|20 |1    |\n",
      "|{2023-02-23 01:02:05.002, 2023-02-23 01:02:15.002}|10 |1    |\n",
      "|{2023-02-23 01:02:20.002, 2023-02-23 01:02:30.002}|50 |1    |\n",
      "|{2023-02-23 01:02:38.002, 2023-02-23 01:02:48.002}|50 |1    |\n",
      "|{2023-02-23 01:01:30.002, 2023-02-23 01:01:43.002}|50 |4    |\n",
      "|{2023-02-23 01:02:37.002, 2023-02-23 01:02:47.002}|30 |1    |\n",
      "|{2023-02-23 01:02:10.002, 2023-02-23 01:02:20.002}|30 |1    |\n",
      "+--------------------------------------------------+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "// Watermarking in Spark Structured Streaming\n",
    "\n",
    "import org.apache.spark.sql.SparkSession\n",
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.sql.types._\n",
    "import org.apache.spark.sql.{DataFrame, Dataset, Encoders, SparkSession}\n",
    "import java.io.IOException\n",
    "import org.apache.spark.sql.streaming._\n",
    "import org.apache.spark.sql.streaming.{GroupState,GroupStateTimeout,OutputMode}\n",
    "import org.apache.spark.sql.DataFrame\n",
    "\n",
    "\n",
    "val PatientsSchema = StructType(Array(\n",
    "     StructField(\"NSS\", StringType),\n",
    "     StructField(\"Nom\", StringType),\n",
    "     StructField(\"DID\", IntegerType),\n",
    "     StructField(\"DNom\", StringType),\n",
    "     StructField(\"Fecha\", StringType)\n",
    "         )\n",
    "    )\n",
    "val spark:SparkSession = SparkSession.builder()\n",
    "    .master(\"local[10]\")\n",
    "    .appName(\"Hand-On-Spark3_Socket_Data_Source\")\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "\n",
    "import spark.implicits._\n",
    "\n",
    "try {\n",
    "    val PatientDS = spark.readStream\n",
    "        .schema(PatientsSchema)\n",
    "        .json(\"/tmp/window\")\n",
    "        .withColumn(\"Fecha\", to_timestamp(col(\"Fecha\"), \"yyyy-MM-dd'T'HH:mm:ss.SSSX\"))\n",
    "    \n",
    "    PatientDS.printSchema()\n",
    "    \n",
    "    printf(\"\\n Listening and ready... \\n\")\n",
    "\n",
    "    val PatientDF = PatientDS\n",
    "        .withWatermark(\"Fecha\", \"30 seconds\")\n",
    "        .groupBy(\n",
    "            session_window(col(\"Fecha\"), \"10 seconds\"), col(\"DID\")\n",
    "        ).count()\n",
    "    \n",
    "    PatientDF.printSchema()\n",
    "    \n",
    "    PatientDF.writeStream\n",
    "        .outputMode(\"complete\")\n",
    "        .format(\"console\")\n",
    "        .option(\"truncate\", false)\n",
    "        .start()\n",
    "        .awaitTermination()\n",
    "    \n",
    "} catch {\n",
    "    case e: IOException => println(\"IOException occurred\")\n",
    "    case t: Throwable => println(\"Error receiving data\", t)\n",
    "}finally {\n",
    "    println(\"In finally block\")\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7abadf9-1868-48fc-84e0-8af4708e4b0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
